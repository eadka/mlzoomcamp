{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torchvision.models as models\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torchvision import transforms\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:12.860231Z","iopub.execute_input":"2025-12-01T20:35:12.860484Z","iopub.status.idle":"2025-12-01T20:35:36.924386Z","shell.execute_reply.started":"2025-12-01T20:35:12.860458Z","shell.execute_reply":"2025-12-01T20:35:36.923793Z"}},"outputs":[{"name":"stderr","text":"2025-12-01 20:35:14.432441: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764621314.652907      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764621314.717669      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"SEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:36.926071Z","iopub.execute_input":"2025-12-01T20:35:36.926541Z","iopub.status.idle":"2025-12-01T20:35:37.013748Z","shell.execute_reply.started":"2025-12-01T20:35:36.926523Z","shell.execute_reply":"2025-12-01T20:35:37.013211Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n!unzip -q data.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:37.014473Z","iopub.execute_input":"2025-12-01T20:35:37.014808Z","iopub.status.idle":"2025-12-01T20:35:38.832169Z","shell.execute_reply.started":"2025-12-01T20:35:37.014783Z","shell.execute_reply":"2025-12-01T20:35:38.831359Z"}},"outputs":[{"name":"stdout","text":"--2025-12-01 20:35:37--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\nResolving github.com (github.com)... 140.82.113.3\nConnecting to github.com (github.com)|140.82.113.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-01T21%3A27%3A16Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-01T20%3A27%3A11Z&ske=2025-12-01T21%3A27%3A16Z&sks=b&skv=2018-11-09&sig=ox20rvTRjkbYK4KK1o8%2BYd9xwZG26BArNxizPZdPPS0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDYyMzEzNywibmJmIjoxNzY0NjIxMzM3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7oZPOtQYHVMkHXKChbilBMg01hHxrDaAnuAKx04AbpA&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n--2025-12-01 20:35:37--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-01T21%3A27%3A16Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-01T20%3A27%3A11Z&ske=2025-12-01T21%3A27%3A16Z&sks=b&skv=2018-11-09&sig=ox20rvTRjkbYK4KK1o8%2BYd9xwZG26BArNxizPZdPPS0%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDYyMzEzNywibmJmIjoxNzY0NjIxMzM3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.7oZPOtQYHVMkHXKChbilBMg01hHxrDaAnuAKx04AbpA&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\nResolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 102516572 (98M) [application/octet-stream]\nSaving to: ‘data.zip’\n\ndata.zip            100%[===================>]  97.77M   250MB/s    in 0.4s    \n\n2025-12-01 20:35:37 (250 MB/s) - ‘data.zip’ saved [102516572/102516572]\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"The shape for input should be (3, 200, 200) (channels first format in PyTorch)","metadata":{}},{"cell_type":"markdown","source":"### Building a CNN","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass HairClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # 1. Convolution: 3 → 32 channels, kernel (3x3)\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n        \n        # 2. Max Pool (2x2)\n        self.pool = nn.MaxPool2d(kernel_size=2)\n        \n        # After conv + pool, compute flattened dimension:\n        # Input: (3, 200, 200)\n        # After conv: (32, 198, 198)\n        # After pool: (32, 99, 99)\n        self.flatten_dim = 32 * 99 * 99\n        \n        # 3. Linear layer with 64 neurons\n        self.fc1 = nn.Linear(self.flatten_dim, 64)\n        \n        # 4. Final binary classifier output\n        self.fc2 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        \n        x = x.view(-1, self.flatten_dim)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)   # output for binary classification\n        return x\n\nmodel = HairClassifier()\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:38.833245Z","iopub.execute_input":"2025-12-01T20:35:38.833532Z","iopub.status.idle":"2025-12-01T20:35:39.005939Z","shell.execute_reply.started":"2025-12-01T20:35:38.833507Z","shell.execute_reply":"2025-12-01T20:35:39.005331Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"HairClassifier(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=313632, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Q1. Which loss function you will use? \nLoss and optimization","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\n\n# optimizer = torch.optim.SGD(\n#     model.parameters(),\n#     lr=0.01,\n#     momentum=0.9\n# )\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:39.006610Z","iopub.execute_input":"2025-12-01T20:35:39.006885Z","iopub.status.idle":"2025-12-01T20:35:39.010814Z","shell.execute_reply.started":"2025-12-01T20:35:39.006866Z","shell.execute_reply":"2025-12-01T20:35:39.010074Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Loss function used: nn.BCEWithLogitsLoss()\n\n✅ nn.BCEWithLogitsLoss() (most correct)\n\n⚠️ nn.MSELoss() (works but suboptimal)\n\n❌ nn.CrossEntropyLoss() (only correct if you change architecture)\n\n❌ nn.CosineEmbeddingLoss() (incorrect- It is for embedding similarity—not classification.)","metadata":{}},{"cell_type":"markdown","source":"### Q2. What's the total number of parameters of the model? You can use torchsummary or count manually.","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:39.011592Z","iopub.execute_input":"2025-12-01T20:35:39.012464Z","iopub.status.idle":"2025-12-01T20:35:39.236614Z","shell.execute_reply.started":"2025-12-01T20:35:39.012446Z","shell.execute_reply":"2025-12-01T20:35:39.236026Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"HairClassifier(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=313632, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=1, bias=True)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Option 1: Using torchsummary (install with: pip install torchsummary)\nfrom torchsummary import summary\nsummary(model, input_size=(3, 200, 200))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:39.238809Z","iopub.execute_input":"2025-12-01T20:35:39.239065Z","iopub.status.idle":"2025-12-01T20:35:39.835344Z","shell.execute_reply.started":"2025-12-01T20:35:39.239050Z","shell.execute_reply":"2025-12-01T20:35:39.834596Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 198, 198]             896\n         MaxPool2d-2           [-1, 32, 99, 99]               0\n            Linear-3                   [-1, 64]      20,072,512\n            Linear-4                    [-1, 1]              65\n================================================================\nTotal params: 20,073,473\nTrainable params: 20,073,473\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.46\nForward/backward pass size (MB): 11.96\nParams size (MB): 76.57\nEstimated Total Size (MB): 89.00\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Total params: 20,073,473\nTrainable params: 20,073,473","metadata":{}},{"cell_type":"markdown","source":"#### Generators and Training","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((200, 200)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ) # ImageNet normalization\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((200, 200)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ) # ImageNet normalization\n])\n\ntrain_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\ntest_dataset  = datasets.ImageFolder(\"data/test\",  transform=test_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\ntest_loader  = DataLoader(test_dataset,  batch_size=20, shuffle=False)\n\nprint(\"Classes:\", train_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:39.836193Z","iopub.execute_input":"2025-12-01T20:35:39.836588Z","iopub.status.idle":"2025-12-01T20:35:39.846584Z","shell.execute_reply.started":"2025-12-01T20:35:39.836559Z","shell.execute_reply":"2025-12-01T20:35:39.845994Z"}},"outputs":[{"name":"stdout","text":"Classes: ['curly', 'straight']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"num_epochs = 10\nhistory = {'acc': [], 'loss': [], 'test_acc': [], 'test_loss': []}\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n        predicted = (torch.sigmoid(outputs) > 0.5).float()\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    epoch_loss = running_loss / len(train_dataset)\n    epoch_acc = correct_train / total_train\n    history['loss'].append(epoch_loss)\n    history['acc'].append(epoch_acc)\n\n    model.eval()\n    test_running_loss = 0.0\n    correct_test = 0\n    total_test = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            labels = labels.float().unsqueeze(1)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            test_running_loss += loss.item() * images.size(0)\n            predicted = (torch.sigmoid(outputs) > 0.5).float()\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_epoch_loss = test_running_loss / len(test_dataset)\n    test_epoch_acc = correct_test / total_test\n    history['test_loss'].append(test_epoch_loss)\n    history['test_acc'].append(test_epoch_acc)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n          f\"Test Loss: {test_epoch_loss:.4f}, Test Acc: {test_epoch_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:35:39.847434Z","iopub.execute_input":"2025-12-01T20:35:39.847744Z","iopub.status.idle":"2025-12-01T20:37:04.695747Z","shell.execute_reply.started":"2025-12-01T20:35:39.847719Z","shell.execute_reply":"2025-12-01T20:37:04.694950Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 0.6665, Acc: 0.6112, Test Loss: 0.6511, Test Acc: 0.6617\nEpoch 2/10, Loss: 0.5702, Acc: 0.6787, Test Loss: 0.6332, Test Acc: 0.6318\nEpoch 3/10, Loss: 0.5207, Acc: 0.7350, Test Loss: 0.6143, Test Acc: 0.6766\nEpoch 4/10, Loss: 0.4773, Acc: 0.7600, Test Loss: 0.6049, Test Acc: 0.6617\nEpoch 5/10, Loss: 0.4606, Acc: 0.7550, Test Loss: 0.7307, Test Acc: 0.5672\nEpoch 6/10, Loss: 0.3954, Acc: 0.8275, Test Loss: 0.6412, Test Acc: 0.6866\nEpoch 7/10, Loss: 0.2844, Acc: 0.8838, Test Loss: 0.8307, Test Acc: 0.6816\nEpoch 8/10, Loss: 0.2885, Acc: 0.8788, Test Loss: 0.7052, Test Acc: 0.7114\nEpoch 9/10, Loss: 0.1882, Acc: 0.9313, Test Loss: 0.9275, Test Acc: 0.6866\nEpoch 10/10, Loss: 0.2585, Acc: 0.8912, Test Loss: 0.8158, Test Acc: 0.6915\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Q3. What is the median of training accuracy for all the epochs for this model?","metadata":{}},{"cell_type":"code","source":"np.median(history['acc'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:37:04.696643Z","iopub.execute_input":"2025-12-01T20:37:04.696907Z","iopub.status.idle":"2025-12-01T20:37:04.703716Z","shell.execute_reply.started":"2025-12-01T20:37:04.696883Z","shell.execute_reply":"2025-12-01T20:37:04.702868Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.79375"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### Question 4. Standard deviation of training loss for all the epochs ","metadata":{}},{"cell_type":"code","source":"np.std(history['loss'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:37:04.704569Z","iopub.execute_input":"2025-12-01T20:37:04.704874Z","iopub.status.idle":"2025-12-01T20:37:04.719319Z","shell.execute_reply.started":"2025-12-01T20:37:04.704851Z","shell.execute_reply":"2025-12-01T20:37:04.718606Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0.14617743215283388"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n    transforms.RandomRotation(50),\n    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ) # ImageNet normalization\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((200, 200)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ) # ImageNet normalization\n])\n\ntrain_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\ntest_dataset  = datasets.ImageFolder(\"data/test\",  transform=test_transforms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\ntest_loader  = DataLoader(test_dataset,  batch_size=20, shuffle=False)\n\nprint(\"Classes:\", train_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:37:04.720619Z","iopub.execute_input":"2025-12-01T20:37:04.720873Z","iopub.status.idle":"2025-12-01T20:37:04.738855Z","shell.execute_reply.started":"2025-12-01T20:37:04.720856Z","shell.execute_reply":"2025-12-01T20:37:04.738310Z"}},"outputs":[{"name":"stdout","text":"Classes: ['curly', 'straight']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"num_epochs = 20\nhistory = {'acc': [], 'loss': [], 'test_acc': [], 'test_loss': []}\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n        predicted = (torch.sigmoid(outputs) > 0.5).float()\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    epoch_loss = running_loss / len(train_dataset)\n    epoch_acc = correct_train / total_train\n    history['loss'].append(epoch_loss)\n    history['acc'].append(epoch_acc)\n\n    model.eval()\n    test_running_loss = 0.0\n    correct_test = 0\n    total_test = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            labels = labels.float().unsqueeze(1)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            test_running_loss += loss.item() * images.size(0)\n            predicted = (torch.sigmoid(outputs) > 0.5).float()\n            total_test += labels.size(0)\n            correct_test += (predicted == labels).sum().item()\n\n    test_epoch_loss = test_running_loss / len(test_dataset)\n    test_epoch_acc = correct_test / total_test\n    history['test_loss'].append(test_epoch_loss)\n    history['test_acc'].append(test_epoch_acc)\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n          f\"Test Loss: {test_epoch_loss:.4f}, Test Acc: {test_epoch_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:37:04.739619Z","iopub.execute_input":"2025-12-01T20:37:04.739830Z","iopub.status.idle":"2025-12-01T20:40:39.526933Z","shell.execute_reply.started":"2025-12-01T20:37:04.739815Z","shell.execute_reply":"2025-12-01T20:40:39.526102Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20, Loss: 0.6307, Acc: 0.6600, Test Loss: 0.5963, Test Acc: 0.7114\nEpoch 2/20, Loss: 0.5801, Acc: 0.6750, Test Loss: 0.5968, Test Acc: 0.7214\nEpoch 3/20, Loss: 0.5374, Acc: 0.7175, Test Loss: 0.5870, Test Acc: 0.7015\nEpoch 4/20, Loss: 0.5502, Acc: 0.7125, Test Loss: 0.5695, Test Acc: 0.7264\nEpoch 5/20, Loss: 0.5250, Acc: 0.7412, Test Loss: 0.6758, Test Acc: 0.6816\nEpoch 6/20, Loss: 0.5141, Acc: 0.7612, Test Loss: 0.5764, Test Acc: 0.7313\nEpoch 7/20, Loss: 0.5217, Acc: 0.7362, Test Loss: 0.5756, Test Acc: 0.6866\nEpoch 8/20, Loss: 0.4888, Acc: 0.7588, Test Loss: 0.5724, Test Acc: 0.7214\nEpoch 9/20, Loss: 0.4989, Acc: 0.7475, Test Loss: 0.5452, Test Acc: 0.7313\nEpoch 10/20, Loss: 0.4663, Acc: 0.7688, Test Loss: 0.5619, Test Acc: 0.7164\nEpoch 11/20, Loss: 0.4634, Acc: 0.7800, Test Loss: 0.6009, Test Acc: 0.6617\nEpoch 12/20, Loss: 0.4530, Acc: 0.7700, Test Loss: 0.5053, Test Acc: 0.7313\nEpoch 13/20, Loss: 0.4420, Acc: 0.7812, Test Loss: 0.5256, Test Acc: 0.7463\nEpoch 14/20, Loss: 0.4625, Acc: 0.7600, Test Loss: 0.5386, Test Acc: 0.7313\nEpoch 15/20, Loss: 0.4510, Acc: 0.7975, Test Loss: 0.5527, Test Acc: 0.7114\nEpoch 16/20, Loss: 0.4508, Acc: 0.7913, Test Loss: 0.5029, Test Acc: 0.7711\nEpoch 17/20, Loss: 0.4115, Acc: 0.8025, Test Loss: 0.5816, Test Acc: 0.7065\nEpoch 18/20, Loss: 0.4262, Acc: 0.7900, Test Loss: 0.5834, Test Acc: 0.7015\nEpoch 19/20, Loss: 0.4172, Acc: 0.8075, Test Loss: 0.6280, Test Acc: 0.6866\nEpoch 20/20, Loss: 0.3988, Acc: 0.8087, Test Loss: 0.4898, Test Acc: 0.7861\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Question 5. Mean of test loss for all the epochs ","metadata":{}},{"cell_type":"code","source":"np.mean(history['test_loss'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:40:39.527794Z","iopub.execute_input":"2025-12-01T20:40:39.528077Z","iopub.status.idle":"2025-12-01T20:40:39.533247Z","shell.execute_reply.started":"2025-12-01T20:40:39.528049Z","shell.execute_reply":"2025-12-01T20:40:39.532578Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.5682816690399279"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Question 6. Average of test accuracy for the last 5 epochs","metadata":{}},{"cell_type":"code","source":"history['test_acc']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:40:39.534062Z","iopub.execute_input":"2025-12-01T20:40:39.534590Z","iopub.status.idle":"2025-12-01T20:40:39.550508Z","shell.execute_reply.started":"2025-12-01T20:40:39.534567Z","shell.execute_reply":"2025-12-01T20:40:39.549911Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[0.7114427860696517,\n 0.7213930348258707,\n 0.7014925373134329,\n 0.7263681592039801,\n 0.681592039800995,\n 0.7313432835820896,\n 0.6865671641791045,\n 0.7213930348258707,\n 0.7313432835820896,\n 0.7164179104477612,\n 0.6616915422885572,\n 0.7313432835820896,\n 0.746268656716418,\n 0.7313432835820896,\n 0.7114427860696517,\n 0.7711442786069652,\n 0.7064676616915423,\n 0.7014925373134329,\n 0.6865671641791045,\n 0.7860696517412935]"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"np.mean(history['test_acc'][-5:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:40:39.551048Z","iopub.execute_input":"2025-12-01T20:40:39.551203Z","iopub.status.idle":"2025-12-01T20:40:39.566297Z","shell.execute_reply.started":"2025-12-01T20:40:39.551191Z","shell.execute_reply":"2025-12-01T20:40:39.565556Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.7303482587064677"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"average_test_acc = sum(history['test_acc'][-5:])/5\naverage_test_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:40:39.566959Z","iopub.execute_input":"2025-12-01T20:40:39.567845Z","iopub.status.idle":"2025-12-01T20:40:39.581620Z","shell.execute_reply.started":"2025-12-01T20:40:39.567809Z","shell.execute_reply":"2025-12-01T20:40:39.580918Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"0.7303482587064677"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}